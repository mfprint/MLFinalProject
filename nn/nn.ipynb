{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martinfigueroapadilla/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import keras\n",
    "import keras.preprocessing.text as kpt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "from keras.initializers import glorot_normal\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 2 2 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martinfigueroapadilla/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "training = np.genfromtxt('data/tweets.csv', delimiter=',', skip_header=1, usecols=(1, 3), dtype=None)\n",
    "\n",
    "train_x = [x[1] for x in training]\n",
    "train_y = np.asarray([x[0] for x in training])\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "dictionary = tokenizer.word_index\n",
    "with open('dictionary.json', 'w') as dictionary_file:\n",
    "    json.dump(dictionary, dictionary_file)\n",
    "\n",
    "def convert_text_to_index_array(text):\n",
    "    return [dictionary[word] for word in kpt.text_to_word_sequence(text)]\n",
    "\n",
    "allWordIndices = []\n",
    "for text in train_x:\n",
    "    wordIndices = convert_text_to_index_array(text)\n",
    "    allWordIndices.append(wordIndices)\n",
    "\n",
    "allWordIndices = np.asarray(allWordIndices)\n",
    "\n",
    "train_x = tokenizer.sequences_to_matrix(allWordIndices, mode='binary')\n",
    "train_y = keras.utils.to_categorical(train_y, max(train_y) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dimension = 3\n",
    "nHidden = 17\n",
    "nInputDimensions = train_x.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(nHidden, input_dim=nInputDimensions, activation='elu', kernel_initializer=glorot_normal(seed=0)))\n",
    "\n",
    "for i in range(0, 7):\n",
    "    model.add(Dense(nHidden, activation='relu', kernel_initializer=glorot_normal(seed=0))) # agregar capa\n",
    "\n",
    "model.add(Dense(out_dimension, activation='sigmoid', kernel_initializer=glorot_normal(seed=0)))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8373 samples, validate on 931 samples\n",
      "Epoch 1/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.4418 - acc: 0.7857 - val_loss: 0.7480 - val_acc: 0.6223\n",
      "Epoch 2/100\n",
      "8373/8373 [==============================] - 13s 1ms/step - loss: 0.2319 - acc: 0.9026 - val_loss: 0.9614 - val_acc: 0.6076\n",
      "Epoch 3/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.1523 - acc: 0.9363 - val_loss: 1.0435 - val_acc: 0.6627\n",
      "Epoch 4/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.1120 - acc: 0.9524 - val_loss: 1.5274 - val_acc: 0.5961\n",
      "Epoch 5/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0932 - acc: 0.9576 - val_loss: 1.6363 - val_acc: 0.6491\n",
      "Epoch 6/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0779 - acc: 0.9639 - val_loss: 1.8009 - val_acc: 0.6728\n",
      "Epoch 7/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0721 - acc: 0.9664 - val_loss: 1.9964 - val_acc: 0.6527\n",
      "Epoch 8/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0662 - acc: 0.9694 - val_loss: 1.8675 - val_acc: 0.6427\n",
      "Epoch 9/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0588 - acc: 0.9732 - val_loss: 2.3012 - val_acc: 0.6319\n",
      "Epoch 10/100\n",
      "8373/8373 [==============================] - 15s 2ms/step - loss: 0.0556 - acc: 0.9732 - val_loss: 3.0257 - val_acc: 0.6097\n",
      "Epoch 11/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0512 - acc: 0.9762 - val_loss: 2.0371 - val_acc: 0.6835\n",
      "Epoch 12/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0498 - acc: 0.9760 - val_loss: 2.4337 - val_acc: 0.6896\n",
      "Epoch 13/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0459 - acc: 0.9759 - val_loss: 2.7656 - val_acc: 0.6438\n",
      "Epoch 14/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0468 - acc: 0.9769 - val_loss: 2.8773 - val_acc: 0.6262\n",
      "Epoch 15/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0461 - acc: 0.9771 - val_loss: 2.7731 - val_acc: 0.6563\n",
      "Epoch 16/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0438 - acc: 0.9791 - val_loss: 2.6698 - val_acc: 0.6642\n",
      "Epoch 17/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0421 - acc: 0.9796 - val_loss: 3.1507 - val_acc: 0.6244\n",
      "Epoch 18/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0417 - acc: 0.9790 - val_loss: 2.7587 - val_acc: 0.6663\n",
      "Epoch 19/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0432 - acc: 0.9788 - val_loss: 2.7650 - val_acc: 0.6566\n",
      "Epoch 20/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0398 - acc: 0.9797 - val_loss: 3.1394 - val_acc: 0.6330\n",
      "Epoch 21/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0386 - acc: 0.9801 - val_loss: 3.5730 - val_acc: 0.6216\n",
      "Epoch 22/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0396 - acc: 0.9801 - val_loss: 3.1649 - val_acc: 0.6441\n",
      "Epoch 23/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0415 - acc: 0.9798 - val_loss: 3.0695 - val_acc: 0.6266\n",
      "Epoch 24/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0386 - acc: 0.9806 - val_loss: 2.6772 - val_acc: 0.6724\n",
      "Epoch 25/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0387 - acc: 0.9807 - val_loss: 3.0077 - val_acc: 0.6649\n",
      "Epoch 26/100\n",
      "8373/8373 [==============================] - 16s 2ms/step - loss: 0.0370 - acc: 0.9820 - val_loss: 2.6166 - val_acc: 0.6767\n",
      "Epoch 27/100\n",
      "8373/8373 [==============================] - 16s 2ms/step - loss: 0.0377 - acc: 0.9811 - val_loss: 3.5879 - val_acc: 0.6040\n",
      "Epoch 28/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0371 - acc: 0.9811 - val_loss: 3.1331 - val_acc: 0.6720\n",
      "Epoch 29/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0363 - acc: 0.9808 - val_loss: 3.9072 - val_acc: 0.6205\n",
      "Epoch 30/100\n",
      "8373/8373 [==============================] - 16s 2ms/step - loss: 0.0368 - acc: 0.9809 - val_loss: 3.9576 - val_acc: 0.6054\n",
      "Epoch 31/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0383 - acc: 0.9810 - val_loss: 3.6232 - val_acc: 0.6538\n",
      "Epoch 32/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0363 - acc: 0.9816 - val_loss: 3.7554 - val_acc: 0.6359\n",
      "Epoch 33/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0356 - acc: 0.9807 - val_loss: 3.7452 - val_acc: 0.6516\n",
      "Epoch 34/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0378 - acc: 0.9815 - val_loss: 3.9031 - val_acc: 0.6330\n",
      "Epoch 35/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0350 - acc: 0.9824 - val_loss: 3.8960 - val_acc: 0.6405\n",
      "Epoch 36/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0354 - acc: 0.9817 - val_loss: 3.1819 - val_acc: 0.6731\n",
      "Epoch 37/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0360 - acc: 0.9822 - val_loss: 4.0075 - val_acc: 0.6480\n",
      "Epoch 38/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0360 - acc: 0.9818 - val_loss: 3.5452 - val_acc: 0.6330\n",
      "Epoch 39/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0351 - acc: 0.9819 - val_loss: 3.5804 - val_acc: 0.6556\n",
      "Epoch 40/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0343 - acc: 0.9817 - val_loss: 3.5216 - val_acc: 0.6584\n",
      "Epoch 41/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0365 - acc: 0.9817 - val_loss: 3.3147 - val_acc: 0.6645\n",
      "Epoch 42/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0339 - acc: 0.9824 - val_loss: 3.6942 - val_acc: 0.6552\n",
      "Epoch 43/100\n",
      "8373/8373 [==============================] - 15s 2ms/step - loss: 0.0353 - acc: 0.9815 - val_loss: 3.7653 - val_acc: 0.6276\n",
      "Epoch 44/100\n",
      "8373/8373 [==============================] - 16s 2ms/step - loss: 0.0347 - acc: 0.9822 - val_loss: 3.0156 - val_acc: 0.6577\n",
      "Epoch 45/100\n",
      "8373/8373 [==============================] - 15s 2ms/step - loss: 0.0353 - acc: 0.9822 - val_loss: 3.3337 - val_acc: 0.6717\n",
      "Epoch 46/100\n",
      "8373/8373 [==============================] - 15s 2ms/step - loss: 0.0342 - acc: 0.9821 - val_loss: 3.5803 - val_acc: 0.6556\n",
      "Epoch 47/100\n",
      "8373/8373 [==============================] - 15s 2ms/step - loss: 0.0343 - acc: 0.9824 - val_loss: 3.5493 - val_acc: 0.6677\n",
      "Epoch 48/100\n",
      "8373/8373 [==============================] - 15s 2ms/step - loss: 0.0337 - acc: 0.9827 - val_loss: 3.3903 - val_acc: 0.6756\n",
      "Epoch 49/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0333 - acc: 0.9822 - val_loss: 3.2677 - val_acc: 0.6806\n",
      "Epoch 50/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0346 - acc: 0.9822 - val_loss: 3.6645 - val_acc: 0.6627\n",
      "Epoch 51/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0334 - acc: 0.9825 - val_loss: 3.9030 - val_acc: 0.6602\n",
      "Epoch 52/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0334 - acc: 0.9826 - val_loss: 4.1093 - val_acc: 0.6559\n",
      "Epoch 53/100\n",
      "8373/8373 [==============================] - 15s 2ms/step - loss: 0.0338 - acc: 0.9832 - val_loss: 3.7455 - val_acc: 0.6513\n",
      "Epoch 54/100\n",
      "8373/8373 [==============================] - 15s 2ms/step - loss: 0.0350 - acc: 0.9816 - val_loss: 3.5611 - val_acc: 0.6781\n",
      "Epoch 55/100\n",
      "8373/8373 [==============================] - 15s 2ms/step - loss: 0.0385 - acc: 0.9817 - val_loss: 3.7303 - val_acc: 0.6563\n",
      "Epoch 56/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0337 - acc: 0.9825 - val_loss: 3.6281 - val_acc: 0.6728\n",
      "Epoch 57/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0339 - acc: 0.9830 - val_loss: 3.8549 - val_acc: 0.6427\n",
      "Epoch 58/100\n",
      "8373/8373 [==============================] - 15s 2ms/step - loss: 0.0345 - acc: 0.9822 - val_loss: 3.8401 - val_acc: 0.6724\n",
      "Epoch 59/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0349 - acc: 0.9822 - val_loss: 3.3691 - val_acc: 0.6989\n",
      "Epoch 60/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0388 - acc: 0.9811 - val_loss: 3.1028 - val_acc: 0.7075\n",
      "Epoch 61/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0342 - acc: 0.9825 - val_loss: 3.7375 - val_acc: 0.6674\n",
      "Epoch 62/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0342 - acc: 0.9825 - val_loss: 4.0425 - val_acc: 0.6498\n",
      "Epoch 63/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0389 - acc: 0.9828 - val_loss: 3.3225 - val_acc: 0.6874\n",
      "Epoch 64/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0346 - acc: 0.9827 - val_loss: 3.5892 - val_acc: 0.6688\n",
      "Epoch 65/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0326 - acc: 0.9830 - val_loss: 3.6914 - val_acc: 0.6781\n",
      "Epoch 66/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0335 - acc: 0.9830 - val_loss: 3.6099 - val_acc: 0.6731\n",
      "Epoch 67/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0349 - acc: 0.9827 - val_loss: 2.9271 - val_acc: 0.6570\n",
      "Epoch 68/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0329 - acc: 0.9828 - val_loss: 3.6306 - val_acc: 0.6649\n",
      "Epoch 69/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0331 - acc: 0.9819 - val_loss: 3.3022 - val_acc: 0.6824\n",
      "Epoch 70/100\n",
      "8373/8373 [==============================] - 16s 2ms/step - loss: 0.0324 - acc: 0.9834 - val_loss: 3.8451 - val_acc: 0.6760\n",
      "Epoch 71/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0332 - acc: 0.9826 - val_loss: 3.5478 - val_acc: 0.6950\n",
      "Epoch 72/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0343 - acc: 0.9814 - val_loss: 4.0718 - val_acc: 0.6538\n",
      "Epoch 73/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0325 - acc: 0.9833 - val_loss: 4.0369 - val_acc: 0.6588\n",
      "Epoch 74/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0322 - acc: 0.9828 - val_loss: 3.9800 - val_acc: 0.6713\n",
      "Epoch 75/100\n",
      "8373/8373 [==============================] - 14s 2ms/step - loss: 0.0323 - acc: 0.9829 - val_loss: 4.0401 - val_acc: 0.6767\n",
      "Epoch 76/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0355 - acc: 0.9826 - val_loss: 4.0545 - val_acc: 0.6574\n",
      "Epoch 77/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0332 - acc: 0.9824 - val_loss: 4.0747 - val_acc: 0.6627\n",
      "Epoch 78/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0401 - acc: 0.9809 - val_loss: 3.5911 - val_acc: 0.6788\n",
      "Epoch 79/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0342 - acc: 0.9830 - val_loss: 3.5668 - val_acc: 0.6932\n",
      "Epoch 80/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0349 - acc: 0.9825 - val_loss: 3.7757 - val_acc: 0.6724\n",
      "Epoch 81/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0334 - acc: 0.9832 - val_loss: 3.6051 - val_acc: 0.6770\n",
      "Epoch 82/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0330 - acc: 0.9827 - val_loss: 3.9789 - val_acc: 0.6523\n",
      "Epoch 83/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0329 - acc: 0.9831 - val_loss: 3.4395 - val_acc: 0.6806\n",
      "Epoch 84/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0321 - acc: 0.9834 - val_loss: 3.9151 - val_acc: 0.6642\n",
      "Epoch 85/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0349 - acc: 0.9822 - val_loss: 3.2651 - val_acc: 0.6917\n",
      "Epoch 86/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0334 - acc: 0.9830 - val_loss: 3.2656 - val_acc: 0.6792\n",
      "Epoch 87/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0322 - acc: 0.9828 - val_loss: 3.6591 - val_acc: 0.6756\n",
      "Epoch 88/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0328 - acc: 0.9828 - val_loss: 3.7336 - val_acc: 0.6488\n",
      "Epoch 89/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0325 - acc: 0.9831 - val_loss: 3.4097 - val_acc: 0.6821\n",
      "Epoch 90/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0328 - acc: 0.9819 - val_loss: 3.6545 - val_acc: 0.6864\n",
      "Epoch 91/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0320 - acc: 0.9831 - val_loss: 3.9147 - val_acc: 0.6874\n",
      "Epoch 92/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0334 - acc: 0.9820 - val_loss: 3.5253 - val_acc: 0.6932\n",
      "Epoch 93/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0332 - acc: 0.9825 - val_loss: 3.6861 - val_acc: 0.6982\n",
      "Epoch 94/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0347 - acc: 0.9827 - val_loss: 3.5157 - val_acc: 0.6924\n",
      "Epoch 95/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0320 - acc: 0.9832 - val_loss: 3.6123 - val_acc: 0.6778\n",
      "Epoch 96/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0325 - acc: 0.9827 - val_loss: 4.0621 - val_acc: 0.6742\n",
      "Epoch 97/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0324 - acc: 0.9831 - val_loss: 3.8904 - val_acc: 0.6713\n",
      "Epoch 98/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0357 - acc: 0.9823 - val_loss: 3.8098 - val_acc: 0.6588\n",
      "Epoch 99/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0321 - acc: 0.9829 - val_loss: 4.0828 - val_acc: 0.6545\n",
      "Epoch 100/100\n",
      "8373/8373 [==============================] - 13s 2ms/step - loss: 0.0323 - acc: 0.9829 - val_loss: 3.7695 - val_acc: 0.6660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2a352550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=5, epochs=100, verbose=1, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open('model.h5', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
